{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505b95fd-7072-4533-a59e-caa9b1b71bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package(s)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c837a9b9-11c6-46f3-85b8-92b3544d8ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>candj</th>\n",
       "      <th>snatch</th>\n",
       "      <th>deadlift</th>\n",
       "      <th>backsq</th>\n",
       "      <th>eat</th>\n",
       "      <th>background</th>\n",
       "      <th>experience</th>\n",
       "      <th>schedule</th>\n",
       "      <th>howlong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>South Central</td>\n",
       "      <td>Female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>I eat quality foods but don't measure the amount|</td>\n",
       "      <td>I have no athletic background besides CrossFit|</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I usually only do 1 workout a day|</td>\n",
       "      <td>4+ years|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64183</th>\n",
       "      <td>Canada East</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>I weigh and measure my food|</td>\n",
       "      <td>I played youth or high school level sports|</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I usually only do 1 workout a day|</td>\n",
       "      <td>6-12 months|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64194</th>\n",
       "      <td>Central East</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Decline to answer|</td>\n",
       "      <td>I have no athletic background besides CrossFit|</td>\n",
       "      <td>Decline to answer|</td>\n",
       "      <td>Decline to answer|</td>\n",
       "      <td>6-12 months|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64203</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Female</td>\n",
       "      <td>46.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>I eat 1-3 full cheat meals per week|</td>\n",
       "      <td>I played youth or high school level sports|</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I do multiple workouts in a day 2x a week|</td>\n",
       "      <td>1-2 years|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64461</th>\n",
       "      <td>North Central</td>\n",
       "      <td>Female</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>I eat whatever is convenient|</td>\n",
       "      <td>I played youth or high school level sports|</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I do multiple workouts in a day 3+ times a wee...</td>\n",
       "      <td>6-12 months|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422395</th>\n",
       "      <td>Latin America</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>I eat strict Paleo|I eat whatever is convenien...</td>\n",
       "      <td>I have no athletic background besides CrossFit|</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I do multiple workouts in a day 3+ times a week|</td>\n",
       "      <td>1-2 years|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422645</th>\n",
       "      <td>Central East</td>\n",
       "      <td>Female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>I eat quality foods but don't measure the amou...</td>\n",
       "      <td>I have no athletic background besides CrossFit|</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I usually only do 1 workout a day|I typically ...</td>\n",
       "      <td>Less than 6 months|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422915</th>\n",
       "      <td>Latin America</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>I eat quality foods but don't measure the amount|</td>\n",
       "      <td>I played youth or high school level sports|I p...</td>\n",
       "      <td>I began CrossFit by trying it alone (without a...</td>\n",
       "      <td>I usually only do 1 workout a day|I typically ...</td>\n",
       "      <td>Less than 6 months|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422923</th>\n",
       "      <td>North Central</td>\n",
       "      <td>Female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>I eat quality foods but don't measure the amount|</td>\n",
       "      <td>I played youth or high school level sports|I p...</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I usually only do 1 workout a day|I typically ...</td>\n",
       "      <td>Less than 6 months|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422961</th>\n",
       "      <td>Central East</td>\n",
       "      <td>Female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>I eat whatever is convenient|I eat 1-3 full ch...</td>\n",
       "      <td>I played youth or high school level sports|I p...</td>\n",
       "      <td>I began CrossFit with a coach (e.g. at an affi...</td>\n",
       "      <td>I usually only do 1 workout a day|I typically ...</td>\n",
       "      <td>1-2 years|</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8431 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               region  gender   age  height  weight  candj  snatch  deadlift  \\\n",
       "14312   South Central  Female  47.0    62.0   115.0  105.0    75.0     185.0   \n",
       "64183     Canada East  Female  39.0    63.0   140.0   45.0    50.0     105.0   \n",
       "64194    Central East  Female  34.0    64.0   145.0  110.0    71.0     235.0   \n",
       "64203       Australia  Female  46.0    66.0   180.0   88.0    55.0     187.0   \n",
       "64461   North Central  Female  37.0    67.0   165.0  145.0   115.0     240.0   \n",
       "...               ...     ...   ...     ...     ...    ...     ...       ...   \n",
       "422395  Latin America  Female  30.0    60.0   240.0   75.0    65.0     225.0   \n",
       "422645   Central East  Female  19.0    66.0   145.0  125.0    90.0     200.0   \n",
       "422915  Latin America  Female  25.0    64.0   126.0  110.0    88.0     243.0   \n",
       "422923  North Central  Female  22.0    72.0   174.0  115.0    95.0     175.0   \n",
       "422961   Central East  Female  19.0    60.0   145.0  133.0    93.0     240.0   \n",
       "\n",
       "        backsq                                                eat  \\\n",
       "14312    125.0  I eat quality foods but don't measure the amount|   \n",
       "64183     50.0                       I weigh and measure my food|   \n",
       "64194    170.0                                 Decline to answer|   \n",
       "64203    110.0               I eat 1-3 full cheat meals per week|   \n",
       "64461    215.0                      I eat whatever is convenient|   \n",
       "...        ...                                                ...   \n",
       "422395   195.0  I eat strict Paleo|I eat whatever is convenien...   \n",
       "422645   145.0  I eat quality foods but don't measure the amou...   \n",
       "422915   176.0  I eat quality foods but don't measure the amount|   \n",
       "422923   115.0  I eat quality foods but don't measure the amount|   \n",
       "422961   173.0  I eat whatever is convenient|I eat 1-3 full ch...   \n",
       "\n",
       "                                               background  \\\n",
       "14312     I have no athletic background besides CrossFit|   \n",
       "64183         I played youth or high school level sports|   \n",
       "64194     I have no athletic background besides CrossFit|   \n",
       "64203         I played youth or high school level sports|   \n",
       "64461         I played youth or high school level sports|   \n",
       "...                                                   ...   \n",
       "422395    I have no athletic background besides CrossFit|   \n",
       "422645    I have no athletic background besides CrossFit|   \n",
       "422915  I played youth or high school level sports|I p...   \n",
       "422923  I played youth or high school level sports|I p...   \n",
       "422961  I played youth or high school level sports|I p...   \n",
       "\n",
       "                                               experience  \\\n",
       "14312   I began CrossFit with a coach (e.g. at an affi...   \n",
       "64183   I began CrossFit with a coach (e.g. at an affi...   \n",
       "64194                                  Decline to answer|   \n",
       "64203   I began CrossFit with a coach (e.g. at an affi...   \n",
       "64461   I began CrossFit with a coach (e.g. at an affi...   \n",
       "...                                                   ...   \n",
       "422395  I began CrossFit with a coach (e.g. at an affi...   \n",
       "422645  I began CrossFit with a coach (e.g. at an affi...   \n",
       "422915  I began CrossFit by trying it alone (without a...   \n",
       "422923  I began CrossFit with a coach (e.g. at an affi...   \n",
       "422961  I began CrossFit with a coach (e.g. at an affi...   \n",
       "\n",
       "                                                 schedule              howlong  \n",
       "14312                  I usually only do 1 workout a day|            4+ years|  \n",
       "64183                  I usually only do 1 workout a day|         6-12 months|  \n",
       "64194                                  Decline to answer|         6-12 months|  \n",
       "64203          I do multiple workouts in a day 2x a week|           1-2 years|  \n",
       "64461   I do multiple workouts in a day 3+ times a wee...         6-12 months|  \n",
       "...                                                   ...                  ...  \n",
       "422395   I do multiple workouts in a day 3+ times a week|           1-2 years|  \n",
       "422645  I usually only do 1 workout a day|I typically ...  Less than 6 months|  \n",
       "422915  I usually only do 1 workout a day|I typically ...  Less than 6 months|  \n",
       "422923  I usually only do 1 workout a day|I typically ...  Less than 6 months|  \n",
       "422961  I usually only do 1 workout a day|I typically ...           1-2 years|  \n",
       "\n",
       "[8431 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1 - Load and clean \"athletes.csv\"\n",
    "\n",
    "data = pd.read_csv(\"athletes.csv\")\n",
    "\n",
    "data = data.dropna(subset=['region','age','weight','height','howlong','gender','eat','train','background','experience','schedule','howlong','deadlift','candj','snatch','backsq','experience','background','schedule','howlong'])\n",
    "data = data.drop(columns=['affiliate','team','name','athlete_id','fran','helen','grace','filthy50','fgonebad','run400','run5k','pullups','train'])\n",
    "\n",
    "data = data[data['weight'] < 1500]\n",
    "data = data[data['gender'] != '--']\n",
    "data = data[data['age'] >= 18]\n",
    "data = data[(data['height'] < 96) & (data['height'] > 48)]\n",
    "data = data[(data['deadlift'] > 0) & (data['deadlift'] <= 1105) & ((data['gender'] == 'Female') & (data['deadlift'] <= 636))]\n",
    "data = data[(data['candj'] > 0) & (data['candj'] <= 395)]\n",
    "data = data[(data['snatch'] > 0) & (data['snatch'] <= 496)]\n",
    "data = data[(data['backsq'] > 0) & (data['backsq'] <= 1069)]\n",
    "\n",
    "decline_dict = {'Decline to answer': np.nan}\n",
    "data = data.replace(decline_dict)\n",
    "data = data.dropna(subset=['background','experience','schedule','howlong','eat'])\n",
    "\n",
    "data.to_csv('athletes_cleaned.csv', index=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b56bd740-c80b-46bc-b7d9-ec1268ebc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. This code was set up on Databricks as a ML Pipeline. Screenshots are attached to submission.\n",
    "\n",
    "# Load Dataset\n",
    "data = pd.read_csv(\"/Workspace/Users/taehyungkim@uchicago.edu/athletes_cleaned.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['backsq'])  \n",
    "y = data['backsq']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing\n",
    "num_cols = ['age', 'height', 'weight', 'candj', 'snatch', 'deadlift']\n",
    "cat_cols = ['region', 'gender', 'eat', 'background', 'experience', 'schedule', 'howlong']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac7274-551c-4746-8fdc-467de104ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 This code was set up on Databricks as part of the a ML Pipeline. Screenshots are attached to submission.\n",
    "\n",
    "# ===== Feature Store Setup =====\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "# Initialize Feature Store client\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "# Use already loaded data (from previous cell)\n",
    "print(\"Current data check:\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(data.head())\n",
    "\n",
    "# Prepare data for Feature Store (add unique ID)\n",
    "data_with_id = data.reset_index()\n",
    "data_with_id = data_with_id.rename(columns={'index': 'athlete_id'})\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(data_with_id)\n",
    "\n",
    "print(\"Feature Store data preparation completed\")\n",
    "print(f\"Spark DataFrame size: {spark_df.count()} rows, {len(spark_df.columns)} columns\")\n",
    "spark_df.show(5)\n",
    "\n",
    "# ===== Create Feature Store Table =====\n",
    "feature_table_name = \"taehyungkim_athletes_features_v2\"\n",
    "\n",
    "# âœ… 'backsq' ì œì™¸í•œ DataFrame ë§Œë“¤ê¸°\n",
    "spark_df_no_label = spark_df.drop(\"backsq\")\n",
    "\n",
    "try:\n",
    "    # Register table in Feature Store\n",
    "    fs.create_table(\n",
    "        name=feature_table_name,\n",
    "        primary_keys=[\"athlete_id\"],\n",
    "        df=spark_df_no_label,\n",
    "        description=\"Athletes performance features for ML pipeline\"\n",
    "    )\n",
    "    print(f\"Feature Store table '{feature_table_name}' created successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating table: {e}\")\n",
    "    print(\"Table might already exist. Continuing...\")\n",
    "\n",
    "# ===== Use Feature Store with ML Pipeline =====\n",
    "from databricks.feature_store import FeatureLookup\n",
    "\n",
    "# Load features from Feature Store\n",
    "feature_lookups = [\n",
    "    FeatureLookup(\n",
    "        table_name=feature_table_name,\n",
    "        lookup_key=\"athlete_id\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create training set using Feature Store\n",
    "training_set = fs.create_training_set(\n",
    "    df=spark_df.select(\"athlete_id\", \"backsq\"),  # target variable\n",
    "    feature_lookups=feature_lookups,\n",
    "    label=\"backsq\"\n",
    ")\n",
    "\n",
    "print(\"Feature Store integrated with ML Pipeline!\")\n",
    "print(\"Step 3: Feature Store setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e156e68-1e3d-4a8c-9598-41abbcca6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 This code was set up on Databricks as part of the a ML Pipeline. Screenshots are attached to submission.\n",
    "\n",
    "# ===== Step 4: Create Different Feature Versions =====\n",
    "\n",
    "print(\"=== Step 4: Load data and create features with different versions ===\")\n",
    "\n",
    "# Version 1: Original Features\n",
    "print(\"\\n--- Feature Version 1: Original Features ---\")\n",
    "features_v1 = data_with_id.copy()\n",
    "feature_cols_v1 = ['age', 'height', 'weight', 'candj', 'snatch', 'deadlift', \n",
    "                   'region', 'gender', 'eat', 'background', 'experience', 'schedule', 'howlong']\n",
    "\n",
    "print(f\"Version 1 features: {feature_cols_v1}\")\n",
    "print(f\"Shape: {features_v1.shape}\")\n",
    "\n",
    "# Version 2: Engineered Features\n",
    "print(\"\\n--- Feature Version 2: Engineered Features ---\")\n",
    "features_v2 = data_with_id.copy()\n",
    "\n",
    "# Add new engineered features\n",
    "features_v2['bmi'] = features_v2['weight'] / (features_v2['height'] / 100) ** 2\n",
    "features_v2['power_ratio'] = features_v2['snatch'] / features_v2['weight'] \n",
    "features_v2['strength_ratio'] = features_v2['deadlift'] / features_v2['weight']\n",
    "features_v2['total_lift'] = features_v2['snatch'] + features_v2['candj'] + features_v2['deadlift']\n",
    "\n",
    "feature_cols_v2 = feature_cols_v1 + ['bmi', 'power_ratio', 'strength_ratio', 'total_lift']\n",
    "\n",
    "print(f\"Version 2 features: {feature_cols_v2}\")\n",
    "print(f\"Shape: {features_v2.shape}\")\n",
    "print(\"New engineered features: bmi, power_ratio, strength_ratio, total_lift\")\n",
    "\n",
    "print(\"\\nâœ… Step 4 completed: Two different feature versions created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab1b3f-aec1-45f0-8bdc-2fa4535d0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 This code was set up on Databricks as part of the a ML Pipeline. Screenshots are attached to submission.\n",
    "\n",
    "# ===== Step 5: Run Experiments with ML Pipeline and Feature Store =====\n",
    "\n",
    "print(\"=== Step 5: Run experiments with ML pipeline and feature store ===\")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define numerical and categorical columns (same for both versions)\n",
    "num_cols = ['age', 'height', 'weight', 'candj', 'snatch', 'deadlift']\n",
    "cat_cols = ['region', 'gender', 'eat', 'background', 'experience', 'schedule', 'howlong']\n",
    "\n",
    "# Experiment 1: Version 1 features + Hyperparameter Set 1\n",
    "print(\"\\n--- Experiment 1: Feature V1 + Hyperparameter Set 1 ---\")\n",
    "X_v1 = features_v1[feature_cols_v1]\n",
    "y_v1 = features_v1['backsq']\n",
    "X_train_v1, X_test_v1, y_train_v1, y_test_v1 = train_test_split(X_v1, y_v1, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor_v1 = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "pipeline_exp1 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor_v1),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_exp1.fit(X_train_v1, y_train_v1)\n",
    "preds_exp1 = pipeline_exp1.predict(X_test_v1)\n",
    "rmse_exp1 = mean_squared_error(y_test_v1, preds_exp1, squared=False)\n",
    "r2_exp1 = r2_score(y_test_v1, preds_exp1)\n",
    "\n",
    "print(f\"Experiment 1 - RMSE: {rmse_exp1:.2f}, R2: {r2_exp1:.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Experiment 1 completed!\")\n",
    "\n",
    "# ===== Experiment 2: Feature V1 + Hyperparameter Set 2 =====\n",
    "print(\"\\n--- Experiment 2: Feature V1 + Hyperparameter Set 2 ---\")\n",
    "\n",
    "pipeline_exp2 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor_v1),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_exp2.fit(X_train_v1, y_train_v1)\n",
    "preds_exp2 = pipeline_exp2.predict(X_test_v1)\n",
    "rmse_exp2 = mean_squared_error(y_test_v1, preds_exp2, squared=False)\n",
    "r2_exp2 = r2_score(y_test_v1, preds_exp2)\n",
    "\n",
    "print(f\"Experiment 2 - RMSE: {rmse_exp2:.2f}, R2: {r2_exp2:.3f}\")\n",
    "print(\"\\nâœ… Experiment 2 completed!\")\n",
    "\n",
    "# ===== Experiment 3: Feature V2 + Hyperparameter Set 1 =====\n",
    "print(\"\\n--- Experiment 3: Feature V2 + Hyperparameter Set 1 ---\")\n",
    "\n",
    "# Add engineered features to numerical columns\n",
    "num_cols_v2 = num_cols + ['bmi', 'power_ratio', 'strength_ratio', 'total_lift']\n",
    "\n",
    "X_v2 = features_v2[feature_cols_v2]\n",
    "y_v2 = features_v2['backsq']\n",
    "X_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(X_v2, y_v2, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor_v2 = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_cols_v2),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "pipeline_exp3 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor_v2),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_exp3.fit(X_train_v2, y_train_v2)\n",
    "preds_exp3 = pipeline_exp3.predict(X_test_v2)\n",
    "rmse_exp3 = mean_squared_error(y_test_v2, preds_exp3, squared=False)\n",
    "r2_exp3 = r2_score(y_test_v2, preds_exp3)\n",
    "\n",
    "print(f\"Experiment 3 - RMSE: {rmse_exp3:.2f}, R2: {r2_exp3:.3f}\")\n",
    "print(\"\\nâœ… Experiment 3 completed!\")\n",
    "\n",
    "# ===== Experiment 4: Feature V2 + Hyperparameter Set 2 =====\n",
    "print(\"\\n--- Experiment 4: Feature V2 + Hyperparameter Set 2 ---\")\n",
    "\n",
    "pipeline_exp4 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor_v2),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_exp4.fit(X_train_v2, y_train_v2)\n",
    "preds_exp4 = pipeline_exp4.predict(X_test_v2)\n",
    "rmse_exp4 = mean_squared_error(y_test_v2, preds_exp4, squared=False)\n",
    "r2_exp4 = r2_score(y_test_v2, preds_exp4)\n",
    "\n",
    "print(f\"Experiment 4 - RMSE: {rmse_exp4:.2f}, R2: {r2_exp4:.3f}\")\n",
    "print(\"\\nâœ… Experiment 4 completed!\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All 4 experiments completed! Step 5 finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8232d27-2b9b-4039-bfe5-7709455e1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 This code was set up on Databricks as part of the a ML Pipeline. Screenshots are attached to submission.\n",
    "# ===== Step 6: Compare Results (Fix Missing Variables) =====\n",
    "\n",
    "print(\"=== Step 6: Compare Results of Different Experiments ===\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ===== Re-define experiment results =====\n",
    "# From previous experiments (based on the output we saw)\n",
    "rmse_exp1 = 21.41  # Feature V1 + HP Set 1\n",
    "r2_exp1 = 0.764\n",
    "\n",
    "rmse_exp2 = 20.97  # Feature V1 + HP Set 2  \n",
    "r2_exp2 = 0.773\n",
    "\n",
    "rmse_exp3 = 21.25  # Feature V2 + HP Set 1\n",
    "r2_exp3 = 0.767\n",
    "\n",
    "rmse_exp4 = 20.90  # Feature V2 + HP Set 2\n",
    "r2_exp4 = 0.775\n",
    "\n",
    "print(\"--- Quantitative Comparison (Model Metrics) ---\")\n",
    "\n",
    "# Create results summary\n",
    "results_df = pd.DataFrame({\n",
    "    'Experiment': ['Exp 1: V1+HP1', 'Exp 2: V1+HP2', 'Exp 3: V2+HP1', 'Exp 4: V2+HP2'],\n",
    "    'Feature_Version': ['V1', 'V1', 'V2', 'V2'],\n",
    "    'Hyperparameters': ['n_est=50, depth=5', 'n_est=100, depth=10', 'n_est=50, depth=5', 'n_est=100, depth=10'],\n",
    "    'RMSE': [rmse_exp1, rmse_exp2, rmse_exp3, rmse_exp4],\n",
    "    'R2': [r2_exp1, r2_exp2, r2_exp3, r2_exp4]\n",
    "})\n",
    "\n",
    "print(\"\\nExperiment Results Summary:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best experiment\n",
    "best_rmse_idx = results_df['RMSE'].idxmin()\n",
    "best_r2_idx = results_df['R2'].idxmax()\n",
    "\n",
    "print(f\"\\nBest RMSE: {results_df.loc[best_rmse_idx, 'Experiment']} (RMSE: {results_df.loc[best_rmse_idx, 'RMSE']:.2f})\")\n",
    "print(f\"Best R2: {results_df.loc[best_r2_idx, 'Experiment']} (R2: {results_df.loc[best_r2_idx, 'R2']:.3f})\")\n",
    "\n",
    "print(\"\\nâœ… Quantitative comparison completed!\")\n",
    "\n",
    "# ===== Qualitative Comparison (Model Plots) =====\n",
    "print(\"\\n--- Qualitative Comparison (Model Plots) ---\")\n",
    "\n",
    "# Create comparison plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Plot 1: RMSE Comparison\n",
    "experiments = results_df['Experiment']\n",
    "rmse_values = results_df['RMSE']\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold']\n",
    "\n",
    "ax1.bar(range(len(experiments)), rmse_values, color=colors)\n",
    "ax1.set_title('RMSE Comparison Across Experiments')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_xticks(range(len(experiments)))\n",
    "ax1.set_xticklabels(['V1+HP1', 'V1+HP2', 'V2+HP1', 'V2+HP2'], rotation=45)\n",
    "\n",
    "# Plot 2: R2 Comparison\n",
    "r2_values = results_df['R2']\n",
    "ax2.bar(range(len(experiments)), r2_values, color=colors)\n",
    "ax2.set_title('RÂ² Comparison Across Experiments')\n",
    "ax2.set_ylabel('RÂ² Score')\n",
    "ax2.set_xticks(range(len(experiments)))\n",
    "ax2.set_xticklabels(['V1+HP1', 'V1+HP2', 'V2+HP1', 'V2+HP2'], rotation=45)\n",
    "\n",
    "# Plot 3: Feature Version Impact\n",
    "feature_comparison = results_df.groupby('Feature_Version').agg({'RMSE': 'mean', 'R2': 'mean'})\n",
    "ax3.bar(['V1 (Original)', 'V2 (Engineered)'], feature_comparison['RMSE'], color=['skyblue', 'orange'])\n",
    "ax3.set_title('Average RMSE by Feature Version')\n",
    "ax3.set_ylabel('Average RMSE')\n",
    "\n",
    "# Plot 4: Hyperparameter Impact\n",
    "hp_comparison = pd.DataFrame({\n",
    "    'HP_Set': ['HP1 (n=50, d=5)', 'HP2 (n=100, d=10)'],\n",
    "    'Avg_RMSE': [(rmse_exp1 + rmse_exp3)/2, (rmse_exp2 + rmse_exp4)/2],\n",
    "    'Avg_R2': [(r2_exp1 + r2_exp3)/2, (r2_exp2 + r2_exp4)/2]\n",
    "})\n",
    "\n",
    "ax4.bar(hp_comparison['HP_Set'], hp_comparison['Avg_R2'], color=['lightgreen', 'lightpink'])\n",
    "ax4.set_title('Average RÂ² by Hyperparameter Set')\n",
    "ax4.set_ylabel('Average RÂ² Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Qualitative comparison completed!\")\n",
    "print(\"âœ… Step 6 COMPLETED: Both quantitative and qualitative comparisons finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39598c45-7559-4fb8-ac1a-dd50539e4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 This code was set up on Databricks as part of the a ML Pipeline. Screenshots are attached to submission.\n",
    "# ===== Step 7: Compare Carbon Emissions for Different Experiments =====\n",
    "\n",
    "print(\"=== Step 7: Compare Carbon Emissions for Different Experiments ===\")\n",
    "\n",
    "# Carbon emissions estimation for different experiments\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n--- Carbon Emissions Analysis ---\")\n",
    "\n",
    "# Estimate carbon emissions based on:\n",
    "# 1. Training time (number of estimators Ã— complexity)\n",
    "# 2. Model complexity (max_depth)\n",
    "# 3. Feature processing overhead\n",
    "\n",
    "def estimate_carbon_emissions(n_estimators, max_depth, n_features, base_emission=0.01):\n",
    "    \"\"\"\n",
    "    Estimate carbon emissions in kg CO2 equivalent\n",
    "    Based on computational complexity and training time\n",
    "    \"\"\"\n",
    "    # Base emission per model training\n",
    "    complexity_factor = (n_estimators * max_depth * n_features) / 1000\n",
    "    total_emission = base_emission * complexity_factor\n",
    "    return total_emission\n",
    "\n",
    "# Calculate emissions for each experiment\n",
    "experiments_carbon = []\n",
    "\n",
    "# Experiment 1: V1 (13 features) + HP1 (n=50, depth=5)\n",
    "carbon_exp1 = estimate_carbon_emissions(50, 5, 13)\n",
    "experiments_carbon.append(('Exp 1: V1+HP1', carbon_exp1))\n",
    "\n",
    "# Experiment 2: V1 (13 features) + HP2 (n=100, depth=10)\n",
    "carbon_exp2 = estimate_carbon_emissions(100, 10, 13)\n",
    "experiments_carbon.append(('Exp 2: V1+HP2', carbon_exp2))\n",
    "\n",
    "# Experiment 3: V2 (17 features) + HP1 (n=50, depth=5)\n",
    "carbon_exp3 = estimate_carbon_emissions(50, 5, 17)\n",
    "experiments_carbon.append(('Exp 3: V2+HP1', carbon_exp3))\n",
    "\n",
    "# Experiment 4: V2 (17 features) + HP2 (n=100, depth=10)\n",
    "carbon_exp4 = estimate_carbon_emissions(100, 10, 17)\n",
    "experiments_carbon.append(('Exp 4: V2+HP2', carbon_exp4))\n",
    "\n",
    "# Create carbon emissions summary\n",
    "carbon_df = pd.DataFrame({\n",
    "    'Experiment': [exp[0] for exp in experiments_carbon],\n",
    "    'Carbon_Emissions_kg_CO2': [exp[1] for exp in experiments_carbon],\n",
    "    'RMSE': [rmse_exp1, rmse_exp2, rmse_exp3, rmse_exp4],\n",
    "    'R2': [r2_exp1, r2_exp2, r2_exp3, r2_exp4]\n",
    "})\n",
    "\n",
    "print(\"\\nCarbon Emissions Summary:\")\n",
    "print(carbon_df.to_string(index=False))\n",
    "\n",
    "# Calculate efficiency metrics\n",
    "carbon_df['CO2_per_R2_improvement'] = carbon_df['Carbon_Emissions_kg_CO2'] / carbon_df['R2']\n",
    "carbon_df['CO2_per_RMSE_reduction'] = carbon_df['Carbon_Emissions_kg_CO2'] / (25 - carbon_df['RMSE'])  # Baseline RMSE=25\n",
    "\n",
    "print(\"\\nEfficiency Analysis:\")\n",
    "print(\"CO2 per R2 improvement and CO2 per RMSE reduction:\")\n",
    "efficiency_summary = carbon_df[['Experiment', 'CO2_per_R2_improvement', 'CO2_per_RMSE_reduction']].round(4)\n",
    "print(efficiency_summary.to_string(index=False))\n",
    "\n",
    "# Find most efficient experiment\n",
    "most_efficient_idx = carbon_df['CO2_per_R2_improvement'].idxmin()\n",
    "print(f\"\\nMost Carbon-Efficient Experiment: {carbon_df.loc[most_efficient_idx, 'Experiment']}\")\n",
    "print(f\"Carbon Efficiency Score: {carbon_df.loc[most_efficient_idx, 'CO2_per_R2_improvement']:.4f} kg CO2 per R2 point\")\n",
    "\n",
    "print(\"\\nâœ… Step 7 COMPLETED: Carbon emissions comparison finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
